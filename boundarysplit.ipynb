{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from functools import partial\n",
    "import nltk\n",
    "from src.contextual_bart import ContextualisedBartModel,BartForContextualRecovery,SimplifiedBeamSearch\n",
    "from src.dataset_processor import load_all_data\n",
    "from src.utils import SmartCollator, get_args, setuptokenizer\n",
    "from src.dataset_processor import (\n",
    "    ContextGenerationDataset,\n",
    ")\n",
    "from transformers import BartTokenizer, BartConfig,BartForConditionalGeneration\n",
    "from src.model_utils import CustomTrainer, get_training_arguments\n",
    "import torch\n",
    "from src.config import DATASET_PATH\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "import pickle as pk\n",
    "import torch\n",
    "from transformers import (    AutoTokenizer,\n",
    "          AutoModelForSeq2SeqLM,\n",
    "         LogitsProcessorList,    MinLengthLogitsProcessor, StoppingCriteriaList, MaxLengthCriteria,\n",
    "         TopKLogitsWarper, TemperatureLogitsWarper,BeamSearchScorer,)\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "DATASET_PATH = \"summarisation_data/\"\n",
    "\n",
    "def generate_data():\n",
    "\n",
    "    # load the dataset\n",
    "\n",
    "    train_data_packet = load_all_data(DATASET_PATH, mode=\"train\")\n",
    "    dev_data_packet = load_all_data(DATASET_PATH, mode=\"dev\")\n",
    "    test_data_packet = load_all_data(DATASET_PATH,mode=\"test\")\n",
    "\n",
    "    print(f\"Training Data size: {len(train_data_packet)}\")\n",
    "    print(f\"Training Data size: {len(test_data_packet)}\")\n",
    "    return train_data_packet,dev_data_packet,test_data_packet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing files:  ['summarisation_data/xsum_train.csv']\n",
      "processing files:  ['summarisation_data/xsum_dev.csv']\n",
      "processing files:  ['summarisation_data/xsum_test.csv']\n",
      "Training Data size: 203083\n",
      "Training Data size: 11322\n"
     ]
    }
   ],
   "source": [
    "train_data_packet,dev_data_packet,test_data_packet = generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from src.dataset_processor import ContextualGenerationData\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "def boundarySplit(data: ContextualGenerationData,\n",
    "                  boundary_limits = (0.25,\n",
    "                                     0.8),\n",
    "                  max_context_tokens=[50,200],\n",
    "                  nb_examples= 3\n",
    "                  ):\n",
    "    data_pack=[]\n",
    "    max_context = np.linspace(max_context_tokens[0],max_context_tokens[-1],num=4)\n",
    "    random.shuffle(max_context)\n",
    "    for idx  in range(nb_examples):\n",
    "        \n",
    "        boundary_portion = np.round(np.random.uniform(\n",
    "                    size=(1,),\n",
    "                    low=boundary_limits[0],\n",
    "                    high=boundary_limits[1],\n",
    "                )[0],2)\n",
    "        d= copy.deepcopy(data)\n",
    "        d.boundary_proportion = (boundary_portion,int(max_context[idx]))\n",
    "        data_pack.append(d)\n",
    "    return data_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff= boundarySplit(train_data_packet[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ContextualGenerationData(input='A Citroen C5, driven by a man, 80, from Stratford-upon-Avon, Warwickshire, and a Jaguar X-Type, driven by a man, 81, of Llandrindod Wells, collided near Walton at 17:30 GMT on Wednesday. Both men were taken to hospital, with the Citroen driver said to be critical. Police said a female passenger in the Jaguar died in hospital on Friday. She had been taken to Queen Elizabeth Hospital, in Birmingham - where the Citroen driver is being treated - after the accident, just over the border from the Herefordshire town of Kington. The force said her next of kin and the coroner have been informed.', output='A woman has died after a collision involving two cars on the A44 in Powys, Dyfed-Powys Police has said.', boundary=-1, focus_txt='', boundary_proportion=(0.79, 50))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = setuptokenizer(\n",
    "        model_base=\"facebook/bart-base\", special_tokens=[], additional_tokens=['[SEP]']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "zz= ff[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage_pack = tokenizer(\n",
    "            zz.input,\n",
    "            add_special_tokens=False,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "passage_seq = passage_pack[\"input_ids\"].flatten()\n",
    "passage_attention = passage_pack[\"attention_mask\"].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([147])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_position = round(passage_seq.shape[0]*zz.boundary_proportion[0])\n",
    "end_position = start_position+ zz.boundary_proportion[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 250, 147)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_position,end_position,passage_seq.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34, 200)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz.boundary_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15268,   583, 14961,    23,   601,    35,   541,  5050,    15,   307,\n",
       "            4,  1868,   604,    58,   551,     7,  1098,     6,    19,     5,\n",
       "         7801,  1001,   225,  1393,    26,     7,    28,  2008,     4,   522,\n",
       "           26,    10,  2182,  4408,    11,     5, 22264,   962,    11,  1098,\n",
       "           15,   273,     4,   264,    56,    57,   551,     7,  3929,  4690,\n",
       "         2392,     6,    11,  8353,   111,   147,     5,  7801,  1001,   225,\n",
       "         1393,    16,   145,  3032,   111,    71,     5,  3213,     6,    95,\n",
       "           81,     5,  1424,    31,     5,  1398,  1891,  9959,  1139,     9,\n",
       "         1745,  1054,     4,    20,  1370,    26,    69,   220,     9, 24438,\n",
       "            8,     5, 16489,    33,    57,  3978,     4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passage_seq[start_position:end_position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "473435c5caf2da67d3d84349b3ab99ae605588908510e1f3cdf041055f6c21f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
