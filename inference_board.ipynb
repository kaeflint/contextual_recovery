{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/nlplab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from functools import partial\n",
    "import nltk\n",
    "from src.contextual_bart import ContextualisedBartModel,BartForContextualRecovery,SimplifiedBeamSearch\n",
    "from src.dataset_processor import load_all_data\n",
    "from src.utils import SmartCollator, get_args, setuptokenizer\n",
    "from src.dataset_processor import (\n",
    "    ContextGenerationDataset,\n",
    ")\n",
    "from transformers import BartTokenizer, BartConfig,BartForConditionalGeneration\n",
    "from src.model_utils import CustomTrainer, get_training_arguments\n",
    "import torch\n",
    "from src.config import DATASET_PATH\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "import pickle as pk\n",
    "import torch\n",
    "from transformers import (    AutoTokenizer,\n",
    "          AutoModelForSeq2SeqLM,\n",
    "         LogitsProcessorList,    MinLengthLogitsProcessor, StoppingCriteriaList, MaxLengthCriteria,\n",
    "         TopKLogitsWarper, TemperatureLogitsWarper,BeamSearchScorer,)\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "DATASET_PATH = \"summarisation_data/\"\n",
    "\n",
    "def generate_tokenizer_and_data(args):\n",
    "\n",
    "    # load the dataset\n",
    "\n",
    "    train_data_packet = load_all_data(DATASET_PATH, mode=\"train\")\n",
    "    dev_data_packet = load_all_data(DATASET_PATH, mode=\"dev\")\n",
    "    test_data_packet = load_all_data(DATASET_PATH,mode=\"test\")\n",
    "\n",
    "    print(f\"Training Data size: {len(train_data_packet)}\")\n",
    "    print(f\"Training Data size: {len(test_data_packet)}\")\n",
    "\n",
    "    model_base = args.model_base\n",
    "    tokenizer = setuptokenizer(\n",
    "        model_base=model_base,\n",
    "        special_tokens=[],\n",
    "    )\n",
    "    tokenizer.add_tokens([args.sep_token])\n",
    "\n",
    "    train_dataset = ContextGenerationDataset(\n",
    "        tokenizer=tokenizer, nb_records=len(train_data_packet), max_len=720,\n",
    "        context_seperator=args.sep_token,\n",
    "        is_auto_encoder_data=not args.is_not_auto_encoder_data,\n",
    "        use_special_token=True,\n",
    "    )\n",
    "    train_dataset.change_data_mode(1)\n",
    "    train_dataset.set_record(train_data_packet)\n",
    "\n",
    "    test_dataset = ContextGenerationDataset(\n",
    "        tokenizer=tokenizer, nb_records=len(test_data_packet), \n",
    "        max_len=700,\n",
    "        context_seperator=args.sep_token,\n",
    "        is_auto_encoder_data=not args.is_not_auto_encoder_data,\n",
    "    )\n",
    "    test_dataset.change_data_mode(1)\n",
    "    test_dataset.set_record(test_data_packet)\n",
    "    \n",
    "    dev_dataset = ContextGenerationDataset(\n",
    "        tokenizer=tokenizer, nb_records=len(dev_data_packet), \n",
    "        max_len=700,\n",
    "        context_seperator=args.sep_token,\n",
    "        is_auto_encoder_data=not args.is_not_auto_encoder_data,\n",
    "    )\n",
    "    test_dataset.change_data_mode(1)\n",
    "    test_dataset.set_record(test_data_packet)\n",
    "\n",
    "    return train_dataset, dev_dataset,test_dataset, [train_data_packet,dev_data_packet,test_data_packet]\n",
    "\n",
    "\n",
    "\n",
    "def model_init(\n",
    "    vocab_size,\n",
    "    context_delimiter_id,\n",
    "    model_base=\"facebook/bart-base\",\n",
    "    use_random_restriction=False,\n",
    "    section_prob=(0.25, 0.45),\n",
    "    device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "):\n",
    "    def build_model():\n",
    "        bart_config = BartConfig.from_pretrained(model_base)\n",
    "        bart_config.context_delimiter_id = context_delimiter_id\n",
    "        bart_config.use_random_restriction = use_random_restriction\n",
    "        bart_config.section_prob = section_prob\n",
    "\n",
    "        generator = BartForContextualRecovery.from_pretrained(\n",
    "            model_base, config=bart_config, ignore_mismatched_sizes=True\n",
    "        )\n",
    "\n",
    "        # update the tokens\n",
    "        generator.resize_token_embeddings(vocab_size)  # type: ignore\n",
    "        return generator.to(device)  # type: ignore\n",
    "    return build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing files:  ['summarisation_data/xsum_train.csv']\n",
      "processing files:  ['summarisation_data/xsum_dev.csv']\n",
      "processing files:  ['summarisation_data/xsum_test.csv']\n",
      "Training Data size: 162548\n",
      "Training Data size: 9049\n",
      "The model will be trained as a non auto-encoder\n",
      "The model will be trained as a non auto-encoder\n",
      "The model will be trained as a non auto-encoder\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Args:\n",
    "    model_base: str\n",
    "    sep_token: str = \"[SEP]\"\n",
    "    is_not_auto_encoder_data: bool = True\n",
    "    \n",
    "    \n",
    "args = Args(model_base=\"facebook/bart-base\")\n",
    "train_dataset, dev_dataset,test_dataset, [train_data_packet,dev_data_packet,test_data_packet] = generate_tokenizer_and_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_delimiter_id = train_dataset.tokenizer.get_vocab()['[SEP]']\n",
    "\n",
    "train_model_path = \"trained_models_sum/bart_base_model_full/checkpoint-81275/pytorch_model.bin\"\n",
    "#\"trained_models_mtl/bart_base_model_full/checkpoint-263195/pytorch_model.bin\"\n",
    "\n",
    "generator = model_init(len(train_dataset.tokenizer),\n",
    "                       context_delimiter_id=context_delimiter_id,\n",
    "                       model_base=args.model_base,use_random_restriction=False)()\n",
    "\n",
    "state_dict = torch.load(train_model_path)\n",
    "generator.load_state_dict(state_dict)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model will be trained as a non auto-encoder\n"
     ]
    }
   ],
   "source": [
    "dataset = ContextGenerationDataset(test_dataset.tokenizer,\n",
    "                                   nb_records=1,\n",
    "                                   section_boundary=(0.4,0.48),\n",
    "                                   \n",
    "        context_seperator=args.sep_token,\n",
    "        is_auto_encoder_data=not args.is_not_auto_encoder_data,\n",
    "                                   use_random_restrictive=True)\n",
    "dataset.change_data_mode(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, torch.Size([1, 158]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataset_processor import ContextualGenerationData\n",
    "from pytorch_lightning import seed_everything\n",
    "data = ContextualGenerationData(input=\"\"\"\n",
    "                                We are helping the community work together towards the goal of advancing Machine Learning üî•.\n",
    "The Hugging Face Hub is a platform with over 60K models, 6K datasets, and 6K demos in which people can easily collaborate in their ML workflows. \n",
    "The Hub works as a central place where anyone can share, explore, discover, and experiment with open-source Machine Learning.\n",
    " No single company, including the Tech Titans, will be able to ‚Äúsolve AI‚Äù by themselves - the only way we'll achieve this is by sharing knowledge and resources in a community-centric approach. We are building the largest open-source collection of models, datasets, demos and metrics on the Hugging Face Hub to democratize and advance ML for everyone üöÄ.\n",
    "                                \"\"\".replace(\"\\n\",\"\").strip(),output=\"\")\n",
    "kk= 45\n",
    "batch = dataset.procesTexts(data)\n",
    "b_input_ids = batch.input_ids.view(1, -1).to(device)\n",
    "b_input_mask = batch.attention_mask.view(1, -1).to(device)\n",
    "batch.section_point, b_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Calls have been made for a room in Wrexham where heroin users can inject safely under supervision.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_packet[kk].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wigan Athletic have signed former Manchester United midfielder Nick Powell on a three-year contract.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_packet[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,SequentialSampler\n",
    "test_data_loader = DataLoader(test_dataset,batch_size=10,\n",
    "                              sampler= SequentialSampler(test_dataset),\n",
    "                              collate_fn= SmartCollator(\n",
    "            pad_token_id=train_dataset.tokenizer.pad_token_id, max_len=700\n",
    "        )\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 593])\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "output_summaries =[]\n",
    "for batch in tqdm.tqdm(test_data_loader):\n",
    "    b_input_ids = batch['input_ids'].to(device)\n",
    "    b_input_mask = batch['attention_mask'].to(device)\n",
    "    bb=generator.generate(input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            num_beams=10,\n",
    "            do_sample=False,\n",
    "            num_return_sequences=1,\n",
    "            max_new_tokens=320)\n",
    "    \n",
    "    sentences = test_dataset.tokenizer.batch_decode(bb,\n",
    "                                                    clean_up_tokenization_spaces=True,\n",
    "                                                    skip_special_tokens=True)\n",
    "    output_summaries+=sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Hugging Face Hub, an open-source machine learning hub, has been launched in New York.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb=generator.generate(input_ids=b_input_ids,\n",
    "            attention_mask=b_input_mask,\n",
    "            num_beams=10,\n",
    "            do_sample=False,\n",
    "            num_return_sequences=1,\n",
    "            max_new_tokens=320)\n",
    "test_dataset.tokenizer.batch_decode(bb,clean_up_tokenization_spaces=True,skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "473435c5caf2da67d3d84349b3ab99ae605588908510e1f3cdf041055f6c21f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
