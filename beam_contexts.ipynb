{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SimplifiedBeamSearch' from 'src.contextual_bart' (/media/nlplab/hdd2/Laith/jojos_work/contextualised_sentence_embedding/src/contextual_bart.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/nlplab/hdd2/Laith/jojos_work/contextualised_sentence_embedding/beam_contexts.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/hdd2/Laith/jojos_work/contextualised_sentence_embedding/beam_contexts.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfunctools\u001b[39;00m \u001b[39mimport\u001b[39;00m partial\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/hdd2/Laith/jojos_work/contextualised_sentence_embedding/beam_contexts.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/hdd2/Laith/jojos_work/contextualised_sentence_embedding/beam_contexts.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcontextual_bart\u001b[39;00m \u001b[39mimport\u001b[39;00m ContextualisedBartModel,BartForContextualRecovery,SimplifiedBeamSearch\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/hdd2/Laith/jojos_work/contextualised_sentence_embedding/beam_contexts.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataset_processor\u001b[39;00m \u001b[39mimport\u001b[39;00m load_all_data\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blaith_server/home/nlplab/hdd2/Laith/jojos_work/contextualised_sentence_embedding/beam_contexts.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m SmartCollator, get_args, setuptokenizer\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SimplifiedBeamSearch' from 'src.contextual_bart' (/media/nlplab/hdd2/Laith/jojos_work/contextualised_sentence_embedding/src/contextual_bart.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from functools import partial\n",
    "import nltk\n",
    "from src.contextual_bart import ContextualisedBartModel,BartForContextualRecovery,SimplifiedBeamSearch\n",
    "from src.dataset_processor import load_all_data\n",
    "from src.utils import SmartCollator, get_args, setuptokenizer\n",
    "from src.dataset_processor import (\n",
    "    ContextGenerationDataset,\n",
    ")\n",
    "from transformers import BartTokenizer, BartConfig,BartForConditionalGeneration\n",
    "from src.model_utils import CustomTrainer, get_training_arguments\n",
    "import torch\n",
    "from src.config import DATASET_PATH\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "import pickle as pk\n",
    "import torch\n",
    "from transformers import (    AutoTokenizer,\n",
    "          AutoModelForSeq2SeqLM,\n",
    "         LogitsProcessorList,    MinLengthLogitsProcessor, StoppingCriteriaList, MaxLengthCriteria,\n",
    "         TopKLogitsWarper, TemperatureLogitsWarper,BeamSearchScorer,)\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "\n",
    "def generate_tokenizer_and_data(args):\n",
    "\n",
    "    # load the dataset\n",
    "\n",
    "    train_data_packet = load_all_data(DATASET_PATH, mode=\"train\")\n",
    "    test_data_packet = load_all_data(DATASET_PATH, mode=\"dev\")\n",
    "\n",
    "    print(f\"Training Data size: {len(train_data_packet)}\")\n",
    "    print(f\"Training Data size: {len(test_data_packet)}\")\n",
    "\n",
    "    model_base = args.model_base\n",
    "    tokenizer = setuptokenizer(\n",
    "        model_base=model_base,\n",
    "        special_tokens=[],\n",
    "    )\n",
    "    tokenizer.add_tokens([\"[SEP]\"])\n",
    "\n",
    "    train_dataset = ContextGenerationDataset(\n",
    "        tokenizer=tokenizer, nb_records=len(train_data_packet),\n",
    "    )\n",
    "    train_dataset.change_data_mode(1)\n",
    "    train_dataset.set_record(train_data_packet)\n",
    "\n",
    "    test_dataset = ContextGenerationDataset(\n",
    "        tokenizer=tokenizer, nb_records=len(test_data_packet), \n",
    "    )\n",
    "    test_dataset.change_data_mode(1)\n",
    "    test_dataset.set_record(test_data_packet)\n",
    "\n",
    "    return train_dataset, test_dataset, [train_data_packet,test_data_packet]\n",
    "\n",
    "\n",
    "\n",
    "def model_init(\n",
    "    vocab_size,\n",
    "    context_delimiter_id,\n",
    "    model_base=\"facebook/bart-base\",\n",
    "    device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "):\n",
    "    bart_config = BartConfig.from_pretrained(model_base)\n",
    "    bart_config.context_delimiter_id = context_delimiter_id\n",
    "\n",
    "    generator = BartForContextualRecovery.from_pretrained(\n",
    "        model_base, config=bart_config, ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    # update the tokens\n",
    "    generator.resize_token_embeddings(vocab_size)  # type: ignore\n",
    "    return generator.to(device)  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing files:  ['processed_data/context_generation_train.csv']\n",
      "processing files:  ['processed_data/context_generation_dev.csv']\n",
      "Training Data size: 145670\n",
      "Training Data size: 12151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Args:\n",
    "    model_base: str\n",
    "    \n",
    "args = Args(model_base=\"facebook/bart-base\")\n",
    "train_dataset, test_dataset,[train_data_packet,test_data_packet] = generate_tokenizer_and_data(args)\n",
    "context_delimiter_id = train_dataset.tokenizer.get_added_vocab()['[SEP]']\n",
    "\n",
    "train_model_path = \"trained_models_mtl/bart_base_model_1/checkpoint-45525/pytorch_model.bin\"\n",
    "\n",
    "generator = model_init(len(train_dataset.tokenizer),\n",
    "                       context_delimiter_id=context_delimiter_id,\n",
    "                       model_base=args.model_base,)\n",
    "\n",
    "state_dict = torch.load(train_model_path)\n",
    "generator.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ContextGenerationDataset(test_dataset.tokenizer,nb_records=1)\n",
    "dataset.change_data_mode(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset_processor import ContextualGenerationData\n",
    "data = ContextualGenerationData(input=\"\"\"Seven (stylized as Se7en) is a 1990 American crime thriller film directed by David Fincher and written by Andrew Kevin Walker. It stars Brad Pitt, Morgan Freeman, Gwyneth Paltrow, and John C. McGinley. [SEP]  Set in a crime-ridden, unnamed city, Seven's plot follows disenchanted, near-retirement detective William Somerset (Freeman) and his new partner, the recently transferred David Mills (Pitt), as they attempt to stop a serial killer before he can complete a series of murders based on the seven deadly sins.\n",
    " \n",
    "                                \"\"\".replace(\"\\n\",\"\").strip(),output=\"\")\n",
    "\n",
    "batch = dataset.procesTexts(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_input_ids = batch.input_ids.view(1, -1).to(device)\n",
    "b_input_mask = batch.attention_mask.view(1, -1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Seven (stylized as Se7en) is a 1990 American crime thriller film directed by David Fincher and written by Andrew Kevin Walker. It stars Brad Pitt, Morgan Freeman, Gwyneth Paltrow, and John C. McGinley.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb= SimplifiedBeamSearch(generator,dataset.tokenizer)\n",
    "bb.generate(input_ids=b_input_ids,attention_mask=b_input_mask,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets run beam search using 3 beams\n",
    "num_beams = 3\n",
    "input_ids = torch.ones((num_beams, 1), device=generator.device, dtype=torch.long)\n",
    "input_ids = input_ids * generator.config.decoder_start_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {   \"encoder_outputs\": generator.get_encoder()( b_input_ids.repeat_interleave(num_beams,dim=0), b_input_mask.repeat_interleave(num_beams,dim=0), return_dict=True\n",
    "        ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_scorer = BeamSearchScorer(  batch_size=4,max_length=generator.config.max_length,num_beams=num_beams,device=generator.device,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_processor = LogitsProcessorList(   [MinLengthLogitsProcessor(5, eos_token_id=generator.config.eos_token_id)] )\n",
    "\n",
    "logits_warper = LogitsProcessorList( [   TopKLogitsWarper(50),    TemperatureLogitsWarper(0.7), ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = generator.beam_sample(input_ids, beam_scorer, logits_processor=logits_processor, logits_warper=logits_warper, **model_kwargs\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "development",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "473435c5caf2da67d3d84349b3ab99ae605588908510e1f3cdf041055f6c21f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
